{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Trends Data\n",
    "This notebook requests trends data on topics, namely relevant terms like destination cities and destination countries. The topic ids have already been collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting country_converter\n",
      "  Downloading country_converter-1.0.0-py3-none-any.whl (44 kB)\n",
      "                                              0.0/44.5 kB ? eta -:--:--\n",
      "     ---------                                10.2/44.5 kB ? eta -:--:--\n",
      "     ---------                                10.2/44.5 kB ? eta -:--:--\n",
      "     ----------------------------------     41.0/44.5 kB 326.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.5/44.5 kB 311.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.0 in c:\\users\\danid\\anaconda3\\envs\\master_thesis\\lib\\site-packages (from country_converter) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danid\\anaconda3\\envs\\master_thesis\\lib\\site-packages (from pandas>=1.0->country_converter) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danid\\anaconda3\\envs\\master_thesis\\lib\\site-packages (from pandas>=1.0->country_converter) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\danid\\anaconda3\\envs\\master_thesis\\lib\\site-packages (from pandas>=1.0->country_converter) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\danid\\anaconda3\\envs\\master_thesis\\lib\\site-packages (from pandas>=1.0->country_converter) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danid\\anaconda3\\envs\\master_thesis\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0->country_converter) (1.16.0)\n",
      "Installing collected packages: country_converter\n",
      "Successfully installed country_converter-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install pytrends\n",
    "#pip install igraph\n",
    "%pip install country_converter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions below is how we make reqeusts to google trends to return trends on keywords.\n",
    "\n",
    "It is a bit of trial and error and a bit of help from [this post](https://stackoverflow.com/a/67199394/10006534).\n",
    "\n",
    "It gathers one term at a time from a list of trends and then if an error occurs (which often happens due to the fact that Google Trends is rate-limited), it sleeps for a minute and repeats the request. If 20 requests are made in a row that result in an error, it will skip that particular request and move on to the next term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pytrends.request import TrendReq\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:109.0) Gecko/20100101 Firefox/112.0',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.5',\n",
    "    # 'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Referer': 'https://trends.google.com/',\n",
    "    'Alt-Used': 'trends.google.com',\n",
    "    'Connection': 'keep-alive',\n",
    "    # 'Cookie': '__utma=10102256.699944976.1681467038.1683327769.1683363479.30; __utmz=10102256.1683363479.30.23.utmcsr=trends.google.com|utmccn=(referral)|utmcmd=referral|utmcct=/; __utmc=10102256; NID=511=GaXIe0Lwd1l8RAGkA2geWNynqviDUhjPBcVgHksJdTnugCvKuUPbm_bM-mT7DhT2jrBHT00aCt71oY7fZhydICB-HNWUzrDnonyPyOGmPTA75lOvpTiguXi3KiGJtRjK3BBH3e1ZcqQ_ywcsU5vHoxJFtH9HGhcLdOt7CL7AWKx8Jj9VSOI3cCwmjDl8gbj2PZ75BU_W4NqspBRMktcdhRitXCyOIqMdLMwZfSOOvFmRBTOJKg8M7UkUTwAVhXtxsKVlHfxPpiWx8HQ63Vr5SV_8qW9f4J0f8EbXWiofQLqpPKJzo0CMbyM-EcnRlR4YVqptEli6EgemOBUJAgH8951i7ANgVDSWy-vn3zXA5KPR5l0LtkriirFZPvsNAmV-_-Mtyuf6gYu8eYJL3g; CONSENT=PENDING+639; SID=WAjkbwUHGFuugy4Yy2rq46Op5ZjRIMvPaLQIAltzHSM35MU0x7YgYongisCrn5htv3RhAw.; __Secure-1PSID=WAjkbwUHGFuugy4Yy2rq46Op5ZjRIMvPaLQIAltzHSM35MU0YH1nUovIFt-jaEUUCx_SIQ.; __Secure-3PSID=WAjkbwUHGFuugy4Yy2rq46Op5ZjRIMvPaLQIAltzHSM35MU0Z8qXUg1LhjB4DtBZWFfNQg.; HSID=A8QJObb1Ve4vQOXFw; SSID=AJr3GRs7Jf_ctBT41; APISID=rNTBsHwZF0AVrKao/AoTWce3Qv8CyFykEc; SAPISID=vftmcyrgIFqWdYpV/AHlhj91rgxiQPlOq8; __Secure-1PAPISID=vftmcyrgIFqWdYpV/AHlhj91rgxiQPlOq8; __Secure-3PAPISID=vftmcyrgIFqWdYpV/AHlhj91rgxiQPlOq8; SIDCC=AP8dLtyjVDmjXvg3rEmTwoLfGyXkY0SDrIFQWqi1z9D1QOL5voioH1Uti_ANGJkiQCuzVd4Axww; __Secure-1PSIDCC=AP8dLtxxVvSKM2MgLGepw_20VZbYsJHar-zF5kvDajRKezVqui3YqxWUaT1e6meVcR9HTUP4lgo; __Secure-3PSIDCC=AP8dLtyyI8BLnakxZZ2OFmPTDfYzPW8jo13jnE34rpPuptgnFDFq-aKX5vfcZdtRDLLZswyAl3gv; 1P_JAR=2023-5-6-12; SOCS=CAISHAgCEhJnd3NfMjAyMjEwMDQtMF9SQzMaAmVuIAEaBgiAwY2aBg; AEC=AUEFqZchyarTzQblW5K5GOTGtYARrs8luJGdx84JVmSwETHSFqijMgs9FA; _ga_VWZPXDNJJB=GS1.1.1683458025.38.1.1683458061.0.0.0; _ga=GA1.3.699944976.1681467038; OTZ=6986051_48_52_123900_48_436380; ADS_VISITOR_ID=00000000-0000-0000-0000-000000000000/112727363205027642159; S=billing-ui-v3=wWfIrmncuOn4LfU6DArDU3LLPpCDgsAT:billing-ui-v3-efe=wWfIrmncuOn4LfU6DArDU3LLPpCDgsAT; __Secure-1PSIDTS=sidts-CjIBLFra0jgJEQyM4EqRZoyaN18X_Umt8M6GTvixMw1pDB_sj5P5XvQokN5dkVw1R2qAkRAA; __Secure-3PSIDTS=sidts-CjIBLFra0jgJEQyM4EqRZoyaN18X_Umt8M6GTvixMw1pDB_sj5P5XvQokN5dkVw1R2qAkRAA; _gid=GA1.3.1220682113.1683458025; _gat_gtag_UA_4401283=1',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    # Requests doesn't support trailers\n",
    "    # 'TE': 'trailers',\n",
    "}\n",
    "\n",
    "def pytrends_request(word_list, country, pytrends):\n",
    "    \n",
    "    pytrends.build_payload(kw_list=word_list, geo=country, timeframe='2005-01-01 2022-12-31')\n",
    "    trends = pytrends.interest_over_time()\n",
    "    if 'isPartial' in trends.columns:\n",
    "        trends.drop('isPartial', axis=1, inplace=True)\n",
    "    # print(word_list)\n",
    "    return trends\n",
    "\n",
    "def get_trends_data(country, keywords):\n",
    "    pytrends = TrendReq(hl='en-US', tz=360, requests_args={'headers': headers})\n",
    "    trends_df = pd.DataFrame()\n",
    "    error_count = 0\n",
    "\n",
    "    for keyword in keywords:\n",
    "        while True:\n",
    "            try:\n",
    "                trends_df = pd.concat([trends_df, pytrends_request([keyword], country, pytrends)], axis=1)\n",
    "                error_count = 0  # Reset error count if successful request\n",
    "                break  # Exit the while loop if successful\n",
    "            except:\n",
    "                error_count += 1\n",
    "                # print('Got an error. Trying again in 60 seconds.')\n",
    "                time.sleep(60)\n",
    "\n",
    "                if error_count == 20:\n",
    "                    print('Reached maximum error count. Exiting loop.')\n",
    "                    return trends_df  # Return the trends_df even if not complete\n",
    "\n",
    "                continue\n",
    "\n",
    "    return trends_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Link Topic Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_topic_ids = pd.read_csv('topic_ids/semantic_topic_ids.csv')\n",
    "countries = pd.read_csv('../../data/clean/unhcr.csv', engine='pyarrow').drop_duplicates('iso_o').Country_o\n",
    "import country_converter as coco\n",
    "iso2_countries = coco.convert(countries, to='iso2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 130/196 [15:39:10<22:20:28, 1218.61s/it]"
     ]
    }
   ],
   "source": [
    "country_trends_list = []\n",
    "for iso2country in tqdm(iso2_countries):\n",
    "    a_country_trends = get_trends_data(iso2country, semantic_topic_ids.topic_id)\n",
    "    a_country_trends['country'] = iso2country\n",
    "    country_trends_list.append(a_country_trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_dict = semantic_topic_ids[['keyword','topic_id']].set_index('topic_id')['keyword'].to_dict()\n",
    "\n",
    "semantic_trends_df = pd.DataFrame()\n",
    "for idx, a_country_semantic_trends in enumerate(country_trends_list):\n",
    "    a_country = a_country_semantic_trends.copy()\n",
    "    if a_country.index.name == 'date':\n",
    "        a_country.reset_index(inplace=True)\n",
    "    if 'index' in a_country.columns.values:\n",
    "        a_country.drop('index',axis=1, inplace=True)\n",
    "    a_country = a_country.loc[:, ~a_country.columns.duplicated()]\n",
    "    # a_country.set_index(['date','country'], inplace=True)\n",
    "    a_country.rename(columns=semantic_dict, inplace=True)\n",
    "    semantic_trends_df = pd.concat([semantic_trends_df, a_country], axis=0, ignore_index=True)\n",
    "\n",
    "semantic_trends_df.to_csv('data/semantic_topic_trends.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Link Keyword trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_topic_ids = pd.read_csv('topic_ids/semantic_topic_ids.csv')\n",
    "countries = pd.read_csv('../../data/data.csv', engine='pyarrow').drop_duplicates('iso_o').Country_o\n",
    "import country_converter as coco\n",
    "iso2_countries = coco.convert(countries, to='iso2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [05:55<00:00, 27.34s/it]\n"
     ]
    }
   ],
   "source": [
    "country_trends_list = []\n",
    "for iso2country in tqdm(iso2_countries):\n",
    "    a_country_trends = get_trends_data(iso2country, semantic_topic_ids.keyword)\n",
    "    a_country_trends['country'] = iso2country\n",
    "    country_trends_list.append(a_country_trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_dict = semantic_topic_ids[['keyword','topic_id']].set_index('topic_id')['keyword'].to_dict()\n",
    "semantic_trends_df = pd.DataFrame()\n",
    "for idx, a_country_semantic_trends in enumerate(country_trends_list):\n",
    "    a_country = a_country_semantic_trends.copy()\n",
    "    if a_country.index.name == 'date':\n",
    "        a_country.reset_index(inplace=True)\n",
    "    if 'index' in a_country.columns.values:\n",
    "        a_country.drop('index',axis=1, inplace=True)\n",
    "    a_country = a_country.loc[:, ~a_country.columns.duplicated()]\n",
    "    # a_country.set_index(['date','country'], inplace=True)\n",
    "    a_country.rename(columns=semantic_dict, inplace=True)\n",
    "    semantic_trends_df = pd.concat([semantic_trends_df, a_country], axis=0, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_trends_df.to_csv('data/semantic_keywords_trends_EN_partial_3.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic links - keywords - original lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from country_abbrev import *\n",
    "from country_language import *\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "import pycountry\n",
    "import itertools\n",
    "\n",
    "from googletrans import LANGCODES\n",
    "import swifter\n",
    "\n",
    "import trends_helpers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_topic_ids = pd.read_csv('topic_ids/semantic_topic_ids.csv')\n",
    "countries = pd.read_csv('../../data/data.csv', engine='pyarrow').drop_duplicates('iso_o').Country_o\n",
    "import country_converter as coco\n",
    "iso2_countries = coco.convert(countries, to='iso2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all unique languages:\n",
    "unique_languages = pd.Series(list(set(list(itertools.chain(*country_language_dict.values())))), name='language')\n",
    "\n",
    "# list of language codes from googletrans\n",
    "langcodes = pd.DataFrame.from_dict(LANGCODES, orient='index', columns=['code'])\n",
    "langcodes.index = langcodes.index.str.capitalize()\n",
    "\n",
    "refugee_lang = unique_languages.to_frame().merge(langcodes, left_on='language', right_index=True, how='left')\n",
    "\n",
    "refugee_lang.dropna(inplace=True)\n",
    "\n",
    "refugee_lang_not_en = refugee_lang[refugee_lang['code'] != 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868a8ee35def4d10adbf9da6ac13e43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translated_keywords = refugee_lang_not_en['code'].swifter.apply(lambda x: trends_helpers.translate_keywords_list(lst = semantic_topic_ids.keyword, lang= x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sn</th>\n",
       "      <th>zu</th>\n",
       "      <th>da</th>\n",
       "      <th>lo</th>\n",
       "      <th>pa</th>\n",
       "      <th>th</th>\n",
       "      <th>cy</th>\n",
       "      <th>el</th>\n",
       "      <th>ro</th>\n",
       "      <th>si</th>\n",
       "      <th>...</th>\n",
       "      <th>my</th>\n",
       "      <th>xh</th>\n",
       "      <th>pl</th>\n",
       "      <th>hi</th>\n",
       "      <th>su</th>\n",
       "      <th>mi</th>\n",
       "      <th>bg</th>\n",
       "      <th>no</th>\n",
       "      <th>ja</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pasipoti</td>\n",
       "      <td>iphasiphothi</td>\n",
       "      <td>pas</td>\n",
       "      <td>ໜັງສືຜ່ານແດນ</td>\n",
       "      <td>ਪਾਸਪੋਰਟ</td>\n",
       "      <td>หนังสือเดินทาง</td>\n",
       "      <td>pasbort</td>\n",
       "      <td>διαβατήριο</td>\n",
       "      <td>pașaport</td>\n",
       "      <td>ගමන් බලපත්ර</td>\n",
       "      <td>...</td>\n",
       "      <td>နိုင်ငံကူးလက်မှတ်</td>\n",
       "      <td>incwadana yokundwendwela</td>\n",
       "      <td>paszport</td>\n",
       "      <td>पासपोर्ट</td>\n",
       "      <td>paspor</td>\n",
       "      <td>uruwhenua</td>\n",
       "      <td>паспорт</td>\n",
       "      <td>pass</td>\n",
       "      <td>パスポート</td>\n",
       "      <td>passport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>immigration</td>\n",
       "      <td>ukuthuthela kwelinye izwe</td>\n",
       "      <td>indvandring</td>\n",
       "      <td>ການ​ອົບ​ພະ​ຍົບ</td>\n",
       "      <td>ਇਮੀਗ੍ਰੇਸ਼ਨ</td>\n",
       "      <td>การตรวจคนเข้าเมือง</td>\n",
       "      <td>mewnfudo</td>\n",
       "      <td>μετανάστευση</td>\n",
       "      <td>imigrare</td>\n",
       "      <td>ආගමන</td>\n",
       "      <td>...</td>\n",
       "      <td>လူဝင်မှုကြီးကြပ်ရေး</td>\n",
       "      <td>ukufudukela kwelinye ilizwe</td>\n",
       "      <td>imigracja</td>\n",
       "      <td>अप्रवासन</td>\n",
       "      <td>imigrasi</td>\n",
       "      <td>te manene</td>\n",
       "      <td>имиграция</td>\n",
       "      <td>innvandring</td>\n",
       "      <td>移民</td>\n",
       "      <td>Immigration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>travel visa</td>\n",
       "      <td>i-visa yokuhamba</td>\n",
       "      <td>rejsevisum</td>\n",
       "      <td>ວີຊາເດີນທາງ</td>\n",
       "      <td>ਯਾਤਰਾ ਵੀਜ਼ਾ</td>\n",
       "      <td>วีซ่าท่องเที่ยว</td>\n",
       "      <td>visa teithio</td>\n",
       "      <td>ταξιδιωτική βίζα</td>\n",
       "      <td>viza de calatorie</td>\n",
       "      <td>සංචාරක වීසා</td>\n",
       "      <td>...</td>\n",
       "      <td>ခရီးသွားဗီဇာ</td>\n",
       "      <td>ivisa yokuhamba</td>\n",
       "      <td>wiza podróżna</td>\n",
       "      <td>यात्रा वीजा</td>\n",
       "      <td>visa perjalanan</td>\n",
       "      <td>visa haerenga</td>\n",
       "      <td>виза за пътуване</td>\n",
       "      <td>reisevisum</td>\n",
       "      <td>旅行ビザ</td>\n",
       "      <td>Travel Visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mupoteri</td>\n",
       "      <td>umbaleki</td>\n",
       "      <td>flygtning</td>\n",
       "      <td>ອົບພະຍົບ</td>\n",
       "      <td>ਸ਼ਰਨਾਰਥੀ</td>\n",
       "      <td>ผู้ลี้ภัย</td>\n",
       "      <td>ffoadur</td>\n",
       "      <td>πρόσφυγας</td>\n",
       "      <td>refugiat</td>\n",
       "      <td>සරණාගතයා</td>\n",
       "      <td>...</td>\n",
       "      <td>ဒုက္ခသည်</td>\n",
       "      <td>imbacu</td>\n",
       "      <td>uchodźca</td>\n",
       "      <td>शरणार्थी</td>\n",
       "      <td>pangungsian</td>\n",
       "      <td>he rerenga</td>\n",
       "      <td>бежанец</td>\n",
       "      <td>flyktning</td>\n",
       "      <td>難民</td>\n",
       "      <td>Refugee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kusawirirana</td>\n",
       "      <td>ukungqubuzana</td>\n",
       "      <td>konflikt</td>\n",
       "      <td>ການຂັດແຍ້ງ</td>\n",
       "      <td>ਟਕਰਾਅ</td>\n",
       "      <td>ขัดแย้ง</td>\n",
       "      <td>gwrthdaro</td>\n",
       "      <td>σύγκρουση</td>\n",
       "      <td>conflict</td>\n",
       "      <td>ගැටුම</td>\n",
       "      <td>...</td>\n",
       "      <td>ပဋိပက္ခ</td>\n",
       "      <td>ungquzulwano</td>\n",
       "      <td>konflikt</td>\n",
       "      <td>टकराव</td>\n",
       "      <td>konflik</td>\n",
       "      <td>taupatupatu</td>\n",
       "      <td>конфликт</td>\n",
       "      <td>konflikt</td>\n",
       "      <td>対立</td>\n",
       "      <td>Conflict</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sn                         zu           da              lo   \n",
       "0      pasipoti               iphasiphothi          pas    ໜັງສືຜ່ານແດນ  \\\n",
       "1   immigration  ukuthuthela kwelinye izwe  indvandring  ການ​ອົບ​ພະ​ຍົບ   \n",
       "2   travel visa           i-visa yokuhamba   rejsevisum     ວີຊາເດີນທາງ   \n",
       "3      mupoteri                   umbaleki    flygtning        ອົບພະຍົບ   \n",
       "4  kusawirirana              ukungqubuzana     konflikt      ການຂັດແຍ້ງ   \n",
       "\n",
       "            pa                  th            cy                el   \n",
       "0      ਪਾਸਪੋਰਟ      หนังสือเดินทาง       pasbort        διαβατήριο  \\\n",
       "1   ਇਮੀਗ੍ਰੇਸ਼ਨ  การตรวจคนเข้าเมือง      mewnfudo      μετανάστευση   \n",
       "2  ਯਾਤਰਾ ਵੀਜ਼ਾ     วีซ่าท่องเที่ยว  visa teithio  ταξιδιωτική βίζα   \n",
       "3     ਸ਼ਰਨਾਰਥੀ           ผู้ลี้ภัย       ffoadur         πρόσφυγας   \n",
       "4        ਟਕਰਾਅ             ขัดแย้ง     gwrthdaro         σύγκρουση   \n",
       "\n",
       "                  ro           si  ...                   my   \n",
       "0           pașaport  ගමන් බලපත්ර  ...    နိုင်ငံကူးလက်မှတ်  \\\n",
       "1           imigrare         ආගමන  ...  လူဝင်မှုကြီးကြပ်ရေး   \n",
       "2  viza de calatorie  සංචාරක වීසා  ...         ခရီးသွားဗီဇာ   \n",
       "3           refugiat     සරණාගතයා  ...             ဒုက္ခသည်   \n",
       "4           conflict        ගැටුම  ...              ပဋိပက္ခ   \n",
       "\n",
       "                            xh             pl           hi               su   \n",
       "0     incwadana yokundwendwela       paszport     पासपोर्ट           paspor  \\\n",
       "1  ukufudukela kwelinye ilizwe      imigracja     अप्रवासन         imigrasi   \n",
       "2              ivisa yokuhamba  wiza podróżna  यात्रा वीजा  visa perjalanan   \n",
       "3                       imbacu       uchodźca     शरणार्थी      pangungsian   \n",
       "4                 ungquzulwano       konflikt        टकराव          konflik   \n",
       "\n",
       "              mi                bg           no     ja           en  \n",
       "0      uruwhenua           паспорт         pass  パスポート     passport  \n",
       "1      te manene         имиграция  innvandring     移民  Immigration  \n",
       "2  visa haerenga  виза за пътуване   reisevisum   旅行ビザ  Travel Visa  \n",
       "3     he rerenga           бежанец    flyktning     難民      Refugee  \n",
       "4    taupatupatu          конфликт     konflikt     対立     Conflict  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(refugee_lang_not_en['code'])\n",
    "\n",
    "df = pd.concat([pd.DataFrame(sublist, columns=[col]) for sublist, col in zip(translated_keywords, columns)], axis=1)\n",
    "\n",
    "df['en']=semantic_topic_ids.keyword\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll only keep two original languages per country\n",
    "\n",
    "country_language_dict_2 = {}\n",
    "\n",
    "for key, values in country_language_dict.items():\n",
    "    country_language_dict_2[key] = values[:2] \n",
    "\n",
    "max_length = max(map(len, country_language_dict_2.values()))\n",
    "\n",
    "data_padded = {key: arr + [np.nan] * (max_length - len(arr)) for key, arr in country_language_dict_2.items()}\n",
    "\n",
    "langs = pd.DataFrame(data_padded)\n",
    "langs = langs.T\n",
    "langs = langs.reset_index()\n",
    "\n",
    "langs = langs.rename(columns={'index': 'Country', 0:'lang1', 1:'lang2', 2:'lang3'})\n",
    "\n",
    "# Apply the function to the 'Country' column\n",
    "langs['ISO2'] = langs['Country'].apply(trends_helpers.get_iso2_country_code)\n",
    "\n",
    "langs = langs.drop(columns=[\"Country\"])\n",
    "langs_long = pd.melt(langs, id_vars=['ISO2'], var_name='numlang', value_name='lang')\n",
    "langs_long = langs_long.dropna()\n",
    "\n",
    "langs_long = pd.merge(langs_long, refugee_lang_not_en, left_on=\"lang\", right_on=\"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [04:25, 44.20s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 42\u001b[0m, in \u001b[0;36mget_trends_data\u001b[1;34m(country, keywords)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     trends_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([trends_df, pytrends_request([keyword], country, pytrends)], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     43\u001b[0m     error_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# Reset error count if successful request\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 27\u001b[0m, in \u001b[0;36mpytrends_request\u001b[1;34m(word_list, country, pytrends)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpytrends_request\u001b[39m(word_list, country, pytrends):\n\u001b[1;32m---> 27\u001b[0m     pytrends\u001b[39m.\u001b[39;49mbuild_payload(kw_list\u001b[39m=\u001b[39;49mword_list, geo\u001b[39m=\u001b[39;49mcountry, timeframe\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m2005-01-01 2022-12-31\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     28\u001b[0m     trends \u001b[39m=\u001b[39m pytrends\u001b[39m.\u001b[39minterest_over_time()\n",
      "File \u001b[1;32mc:\\Users\\danid\\anaconda3\\envs\\master_thesis\\Lib\\site-packages\\pytrends\\request.py:189\u001b[0m, in \u001b[0;36mTrendReq.build_payload\u001b[1;34m(self, kw_list, cat, timeframe, geo, gprop)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39m# get tokens\u001b[39;00m\n\u001b[1;32m--> 189\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokens()\n\u001b[0;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danid\\anaconda3\\envs\\master_thesis\\Lib\\site-packages\\pytrends\\request.py:195\u001b[0m, in \u001b[0;36mTrendReq._tokens\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39m# make the request and parse the returned json\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m widget_dicts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data(\n\u001b[0;32m    196\u001b[0m     url\u001b[39m=\u001b[39;49mTrendReq\u001b[39m.\u001b[39;49mGENERAL_URL,\n\u001b[0;32m    197\u001b[0m     method\u001b[39m=\u001b[39;49mTrendReq\u001b[39m.\u001b[39;49mPOST_METHOD,\n\u001b[0;32m    198\u001b[0m     params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken_payload,\n\u001b[0;32m    199\u001b[0m     trim_chars\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,\n\u001b[0;32m    200\u001b[0m )[\u001b[39m'\u001b[39m\u001b[39mwidgets\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    201\u001b[0m \u001b[39m# order of the json matters...\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danid\\anaconda3\\envs\\master_thesis\\Lib\\site-packages\\pytrends\\request.py:136\u001b[0m, in \u001b[0;36mTrendReq._get_data\u001b[1;34m(self, url, method, trim_chars, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m TrendReq\u001b[39m.\u001b[39mPOST_METHOD:\n\u001b[1;32m--> 136\u001b[0m     response \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39;49mpost(url, timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[0;32m    137\u001b[0m                       cookies\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcookies, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    138\u001b[0m                       \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequests_args)  \u001b[39m# DO NOT USE retries or backoff_factor here\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\danid\\anaconda3\\envs\\master_thesis\\Lib\\site-packages\\requests\\sessions.py:635\u001b[0m, in \u001b[0;36mSession.post\u001b[1;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\danid\\anaconda3\\envs\\master_thesis\\Lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\danid\\anaconda3\\envs\\master_thesis\\Lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danid\\anaconda3\\envs\\master_thesis\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\danid\\anaconda3\\envs\\master_thesis\\Lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danid\\anaconda3\\envs\\master_thesis\\Lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    387\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    388\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danid\\anaconda3\\envs\\master_thesis\\Lib\\site-packages\\urllib3\\connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\danid\\anaconda3\\envs\\master_thesis\\Lib\\site-packages\\urllib3\\connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    417\u001b[0m     context\u001b[39m.\u001b[39mload_default_certs()\n\u001b[1;32m--> 419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    420\u001b[0m     sock\u001b[39m=\u001b[39;49mconn,\n\u001b[0;32m    421\u001b[0m     keyfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_file,\n\u001b[0;32m    422\u001b[0m     certfile\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcert_file,\n\u001b[0;32m    423\u001b[0m     key_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkey_password,\n\u001b[0;32m    424\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[0;32m    425\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[0;32m    426\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[0;32m    427\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    428\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mcontext,\n\u001b[0;32m    429\u001b[0m     tls_in_tls\u001b[39m=\u001b[39;49mtls_in_tls,\n\u001b[0;32m    430\u001b[0m )\n\u001b[0;32m    432\u001b[0m \u001b[39m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[39m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[39m# for the host.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danid\\anaconda3\\envs\\master_thesis\\Lib\\site-packages\\urllib3\\util\\ssl_.py:402\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 402\u001b[0m     context\u001b[39m.\u001b[39;49mload_verify_locations(ca_certs, ca_cert_dir, ca_cert_data)\n\u001b[0;32m    403\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIOError\u001b[39;00m, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i, country \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(langs_long[\u001b[39m\"\u001b[39m\u001b[39mISO2\u001b[39m\u001b[39m\"\u001b[39m])):\n\u001b[0;32m      4\u001b[0m     languagecode\u001b[39m=\u001b[39m langs_long[\u001b[39m\"\u001b[39m\u001b[39mcode\u001b[39m\u001b[39m\"\u001b[39m][i]\n\u001b[1;32m----> 5\u001b[0m     a_country_trends \u001b[39m=\u001b[39m get_trends_data(country, df[langs_long[\u001b[39m\"\u001b[39;49m\u001b[39mcode\u001b[39;49m\u001b[39m\"\u001b[39;49m][i]])\n\u001b[0;32m      6\u001b[0m     a_country_trends[\u001b[39m'\u001b[39m\u001b[39mcountry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m country\n\u001b[0;32m      7\u001b[0m     country_trends_list\u001b[39m.\u001b[39mappend(a_country_trends)\n",
      "Cell \u001b[1;32mIn[8], line 48\u001b[0m, in \u001b[0;36mget_trends_data\u001b[1;34m(country, keywords)\u001b[0m\n\u001b[0;32m     46\u001b[0m error_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     47\u001b[0m \u001b[39m# print('Got an error. Trying again in 60 seconds.')\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m60\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[39mif\u001b[39;00m error_count \u001b[39m==\u001b[39m \u001b[39m20\u001b[39m:\n\u001b[0;32m     51\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mReached maximum error count. Exiting loop.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "country_trends_list = [] \n",
    "\n",
    "for i, country in tqdm(enumerate(langs_long[\"ISO2\"])):\n",
    "    languagecode= langs_long[\"code\"][i]\n",
    "    a_country_trends = get_trends_data(country, df[langs_long[\"code\"][i]])\n",
    "    a_country_trends['country'] = country\n",
    "    country_trends_list.append(a_country_trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update column names to english, but having a choice to \n",
    "# keep track of what the language of search was (wide==True)\n",
    "\n",
    "def update_column_names(data_list, original_lang_code, wide:bool):\n",
    "    \n",
    "    mapping_dict = dict(zip(df[original_lang_code], df['en']))\n",
    "\n",
    "    new_data_list = []\n",
    "    for data in data_list:\n",
    "        new_data = data.copy()  # Make a copy of the DataFrame\n",
    "        new_columns = []\n",
    "\n",
    "        if wide==True:\n",
    "\n",
    "            for column in new_data.columns:\n",
    "                if column in mapping_dict:\n",
    "                    new_column = f\"{mapping_dict[column]}_{original_lang_code}\"\n",
    "                else:\n",
    "                    new_column = column\n",
    "                new_columns.append(new_column)\n",
    "            new_data.columns = new_columns\n",
    "        \n",
    "        else:\n",
    "\n",
    "            for column in new_data.columns:\n",
    "                if column in mapping_dict:\n",
    "                    new_column = f\"{mapping_dict[column]}\"\n",
    "                else:\n",
    "                    new_column = column\n",
    "                new_columns.append(new_column)\n",
    "            new_data.columns = new_columns\n",
    "\n",
    "\n",
    "        new_data_list.append(new_data)  # Add the modified DataFrame to the new list\n",
    "\n",
    "\n",
    "    return new_data_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short version\n",
    "\n",
    "updated_data_list = country_trends_list.copy()\n",
    "for lang in langs_long[\"code\"][:len(country_trends_list)]:\n",
    "    updated_data_list = update_column_names(updated_data_list, lang, wide=False)\n",
    "\n",
    "# Detailed version\n",
    "\n",
    "updated_data_list_detailed = country_trends_list.copy()\n",
    "for lang in langs_long[\"code\"][:len(country_trends_list)]:\n",
    "    updated_data_list_detailed = update_column_names(updated_data_list_detailed, lang, wide=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_dict = semantic_topic_ids[['keyword','topic_id']].set_index('topic_id')['keyword'].to_dict()\n",
    "semantic_trends_df = pd.DataFrame()\n",
    "for idx, a_country_semantic_trends in enumerate(updated_data_list):\n",
    "    a_country = a_country_semantic_trends.copy()\n",
    "    if a_country.index.name == 'date':\n",
    "        a_country.reset_index(inplace=True)\n",
    "    if 'index' in a_country.columns.values:\n",
    "        a_country.drop('index',axis=1, inplace=True)\n",
    "    a_country = a_country.loc[:, ~a_country.columns.duplicated()]\n",
    "    # a_country.set_index(['date','country'], inplace=True)\n",
    "    a_country.rename(columns=semantic_dict, inplace=True)\n",
    "    semantic_trends_df = pd.concat([semantic_trends_df, a_country], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>passport</th>\n",
       "      <th>Immigration</th>\n",
       "      <th>War</th>\n",
       "      <th>Crisis</th>\n",
       "      <th>Civilian</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Lottery</th>\n",
       "      <th>Economy</th>\n",
       "      <th>Coup d’état</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>Conflict</th>\n",
       "      <th>Violence</th>\n",
       "      <th>Genocide</th>\n",
       "      <th>Armed Forces</th>\n",
       "      <th>Protest</th>\n",
       "      <th>Travel Visa</th>\n",
       "      <th>Refugee</th>\n",
       "      <th>Militia</th>\n",
       "      <th>Wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005-03-01</td>\n",
       "      <td>100.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005-05-01</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>AF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>BH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>BH</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>BH</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>BH</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>BH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  passport  Immigration  War  Crisis  Civilian  Currency   \n",
       "0    2005-01-01       0.0        100.0    0       0         0       0.0  \\\n",
       "1    2005-02-01       0.0          0.0    0     100         0       0.0   \n",
       "2    2005-03-01     100.0         69.0    0       0         0       0.0   \n",
       "3    2005-04-01       0.0          0.0    0       0         0       0.0   \n",
       "4    2005-05-01      62.0          0.0    0       0         0       0.0   \n",
       "...         ...       ...          ...  ...     ...       ...       ...   \n",
       "1291 2022-08-01       9.0         12.0   16       7         4      34.0   \n",
       "1292 2022-09-01       5.0         11.0   10       4         6      34.0   \n",
       "1293 2022-10-01       5.0          9.0   12       3         3      35.0   \n",
       "1294 2022-11-01       7.0         21.0   12       0         7      22.0   \n",
       "1295 2022-12-01       9.0          7.0    8       3         4      33.0   \n",
       "\n",
       "      Lottery  Economy  Coup d’état  ...  country Conflict  Violence   \n",
       "0           0        0         60.0  ...       AF      NaN       NaN  \\\n",
       "1           0        0          0.0  ...       AF      NaN       NaN   \n",
       "2         100      100          0.0  ...       AF      NaN       NaN   \n",
       "3           0        0          0.0  ...       AF      NaN       NaN   \n",
       "4           0       52         31.0  ...       AF      NaN       NaN   \n",
       "...       ...      ...          ...  ...      ...      ...       ...   \n",
       "1291        0        4          NaN  ...       BH      5.0       4.0   \n",
       "1292        0        3          NaN  ...       BH      6.0       3.0   \n",
       "1293        0        0          NaN  ...       BH      3.0       3.0   \n",
       "1294        9        6          NaN  ...       BH      3.0       2.0   \n",
       "1295        0        2          NaN  ...       BH      0.0       8.0   \n",
       "\n",
       "      Genocide  Armed Forces  Protest  Travel Visa  Refugee  Militia  Wage  \n",
       "0          NaN           NaN      NaN          NaN      NaN      NaN   NaN  \n",
       "1          NaN           NaN      NaN          NaN      NaN      NaN   NaN  \n",
       "2          NaN           NaN      NaN          NaN      NaN      NaN   NaN  \n",
       "3          NaN           NaN      NaN          NaN      NaN      NaN   NaN  \n",
       "4          NaN           NaN      NaN          NaN      NaN      NaN   NaN  \n",
       "...        ...           ...      ...          ...      ...      ...   ...  \n",
       "1291       NaN           8.0      3.0          NaN      NaN      NaN   0.0  \n",
       "1292       NaN           0.0      2.0          NaN      NaN      NaN   2.0  \n",
       "1293       NaN           0.0      0.0          NaN      NaN      NaN   3.0  \n",
       "1294       NaN           0.0      0.0          NaN      NaN      NaN   0.0  \n",
       "1295       NaN           0.0      2.0          NaN      NaN      NaN   0.0  \n",
       "\n",
       "[1296 rows x 21 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_trends_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighboring Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import igraph as ig\n",
    "import country_converter as coco\n",
    "\n",
    "# convert unhcr data to network format. To produce the unhcr.csv file, you will need to:\n",
    "# # drag and drop the data.csv file from geraldine into the data/raw/ folder\n",
    "# # open the clean_data.ipynb notebook in data/\n",
    "# # run the section that cleans the unhcr data, which outputs unhcr.csv into data/clean/\n",
    "unhcr = pd.read_csv('../../data/clean/unhcr.csv', engine='pyarrow').groupby(['iso_o','iso_d']).agg({'newarrival':'sum','contig':'first','Country_o':'first','Country_d':'first', 'island_o':'first'}).reset_index()\n",
    "\n",
    "df_network = unhcr[unhcr.contig == 1]\n",
    "\n",
    "graph = ig.Graph.TupleList(df_network[['Country_o','Country_d']].itertuples(index=False), directed=False)\n",
    "\n",
    "# add island countries \n",
    "islands = unhcr.drop_duplicates('Country_o').sort_values('Country_o').Country_o[~unhcr.groupby('Country_o')['contig'].any().values].values\n",
    "\n",
    "for i in islands:\n",
    "    v = graph.add_vertex()\n",
    "    # Set the name or other properties of the added vertex if needed\n",
    "    v['name'] = i\n",
    "\n",
    "graph.vs['name'] = coco.convert(graph.vs['name'], to='iso2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get country topic ids\n",
    "country_topic_ids = pd.read_csv('topic_ids/country_topic_ids.csv')\n",
    "country_topic_ids['iso2'] = coco.convert(country_topic_ids.search, to='iso2')\n",
    "country_topic_dict = country_topic_ids[['topic_title', 'topic_mid']].set_index('topic_mid')['topic_title'].to_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get neighboring countries of order 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [06:31<00:00,  3.73s/it]\n"
     ]
    }
   ],
   "source": [
    "# list of countries\n",
    "iso2_countries = coco.convert(unhcr.Country_o.unique(), to='iso2')\n",
    "\n",
    "country_trends_list = []\n",
    "last_index = iso2_countries.index('KG') + 1\n",
    "for iso2country in tqdm(iso2_countries[last_index:]):\n",
    "    # get neighbors of country\n",
    "    neighboring_countries = graph.vs[graph.neighborhood(iso2country, order=1)]['name'][1:]\n",
    "\n",
    "    order1_countries = country_topic_ids[country_topic_ids.iso2.isin(neighboring_countries)]\n",
    "\n",
    "    a_country_trends = get_trends_data(iso2country, order1_countries.topic_mid)\n",
    "    a_country_trends['country_o'] = iso2country\n",
    "    # a_country_trends['country_d','city_d'] = order1_countries[['search_keyword','topic_title']]\n",
    "    country_trends_list.append(a_country_trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into a single dataframe\n",
    "countries_trends_df = pd.DataFrame()\n",
    "for _, a_country_trends in enumerate(country_trends_list):\n",
    "    countries_trends_df = pd.concat([countries_trends_df, a_country_trends], axis=0)\n",
    "\n",
    "# Before writing to a csv, make sure that the output makes sense, I think there should be a lot of nas and a lot of columns, one for each country/city topic. \n",
    "# The only ones that aren't na should be the neighboring countries for that country\n",
    "\n",
    "# countries_trends_df = countries_trends_df.reset_index().rename({'index':'date'},axis=1).set_index(['country', 'date'])\n",
    "countries_trends_df.to_csv('data/country_topic_trends_1.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can gather trends for countries of order 2, excluding order 1 \n",
    "\n",
    "(I think we can skp this part for now. There needs to be some distance-based filter as well that omits far away countries, Looking at Afghanistan for example yields too many countries/cities).\n",
    "\n",
    "This could be obtained by merging countries with the unhcr distance measurments between countries, and omitting countries above a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search</th>\n",
       "      <th>topic_title</th>\n",
       "      <th>topic_type</th>\n",
       "      <th>topic_mid</th>\n",
       "      <th>iso2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>Armenia</td>\n",
       "      <td>Country in Asia</td>\n",
       "      <td>/m/0jgx</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>Country</td>\n",
       "      <td>/m/0jhd</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>Bhutan</td>\n",
       "      <td>Country in South Asia</td>\n",
       "      <td>/m/07bxhl</td>\n",
       "      <td>BT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Hong Kong SAR</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>Special administrative regions of China</td>\n",
       "      <td>/m/03h64</td>\n",
       "      <td>HK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>India</td>\n",
       "      <td>India</td>\n",
       "      <td>Country in South Asia</td>\n",
       "      <td>/m/03rk0</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Iraq</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>Country in the Middle East</td>\n",
       "      <td>/m/0d05q4</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>Country in Central Asia</td>\n",
       "      <td>/m/047lj</td>\n",
       "      <td>KZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Kyrgyz Republic</td>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>Country in Central Asia</td>\n",
       "      <td>/m/0jt3tjf</td>\n",
       "      <td>KG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Lao P.D.R.</td>\n",
       "      <td>Laos</td>\n",
       "      <td>Country in Asia</td>\n",
       "      <td>/m/04hhv</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Macao SAR</td>\n",
       "      <td>Macao</td>\n",
       "      <td>Special administrative regions of China</td>\n",
       "      <td>/m/04thp</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Mongolia</td>\n",
       "      <td>Mongolia</td>\n",
       "      <td>Country in East Asia</td>\n",
       "      <td>/m/04w8f</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Myanmar</td>\n",
       "      <td>Myanmar (Burma)</td>\n",
       "      <td>Country in Asia</td>\n",
       "      <td>/m/04xn_</td>\n",
       "      <td>MM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Nepal</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>Country in South Asia</td>\n",
       "      <td>/m/016zwt</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Russia</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Country</td>\n",
       "      <td>/m/06bnz</td>\n",
       "      <td>RU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Türkiye</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>Country in the Middle East</td>\n",
       "      <td>/m/01znc_</td>\n",
       "      <td>TR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Country in Asia</td>\n",
       "      <td>/m/01crd5</td>\n",
       "      <td>VN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              search      topic_title  \\\n",
       "6            Armenia          Armenia   \n",
       "10        Azerbaijan       Azerbaijan   \n",
       "19            Bhutan           Bhutan   \n",
       "73     Hong Kong SAR        Hong Kong   \n",
       "76             India            India   \n",
       "79              Iraq             Iraq   \n",
       "86        Kazakhstan       Kazakhstan   \n",
       "92   Kyrgyz Republic       Kyrgyzstan   \n",
       "93        Lao P.D.R.             Laos   \n",
       "101        Macao SAR            Macao   \n",
       "114         Mongolia         Mongolia   \n",
       "118          Myanmar  Myanmar (Burma)   \n",
       "121            Nepal            Nepal   \n",
       "142           Russia           Russia   \n",
       "178          Türkiye          Türkiye   \n",
       "190          Vietnam          Vietnam   \n",
       "\n",
       "                                  topic_type   topic_mid iso2  \n",
       "6                            Country in Asia     /m/0jgx   AM  \n",
       "10                                   Country     /m/0jhd   AZ  \n",
       "19                     Country in South Asia   /m/07bxhl   BT  \n",
       "73   Special administrative regions of China    /m/03h64   HK  \n",
       "76                     Country in South Asia    /m/03rk0   IN  \n",
       "79                Country in the Middle East   /m/0d05q4   IQ  \n",
       "86                   Country in Central Asia    /m/047lj   KZ  \n",
       "92                   Country in Central Asia  /m/0jt3tjf   KG  \n",
       "93                           Country in Asia    /m/04hhv   LA  \n",
       "101  Special administrative regions of China    /m/04thp   MO  \n",
       "114                     Country in East Asia    /m/04w8f   MN  \n",
       "118                          Country in Asia    /m/04xn_   MM  \n",
       "121                    Country in South Asia   /m/016zwt   NP  \n",
       "142                                  Country    /m/06bnz   RU  \n",
       "178               Country in the Middle East   /m/01znc_   TR  \n",
       "190                          Country in Asia   /m/01crd5   VN  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighboring_countries_order2 = list(set(graph.vs[graph.neighborhood('AF', order=2)]['name']) - set(graph.vs[graph.neighborhood('AF', order=1)]['name']))\n",
    "\n",
    "# too many countries for order 2.\n",
    "country_topic_ids[country_topic_ids.iso2.isin(neighboring_countries_order2)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also gather trends for countries that are relevant but are not directly connected (i.e., Dominican Republic for Venezuela)\n",
    "\n",
    "- For South American and Latin American countries, let’s say we add Spain, Chile, Argentina, USA, and Dominican Republic.\n",
    "- For African countries + middle east, include the top 6 most receptive countries in Europe (Germany, France, Great Britain, Sweden, Austria, Hungary, Italy or something). In Carramia et al they also added likely countries that peopel in Africa would have to pass through to get to Europe which could be interesting to consider.\n",
    "- China and India we can add the US.\n",
    "\n",
    "There is room to refine this. Not sure how broad/specific this should be."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighboring Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get city topic ids\n",
    "city_topic_ids = pd.read_csv('topic_ids/city_topic_id.csv')\n",
    "city_topic_ids['iso2'] = coco.convert(city_topic_ids.search_country, to='iso2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can gather all the cities of neighboring countries of order 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [2:30:52<00:00, 46.19s/it]   \n"
     ]
    }
   ],
   "source": [
    "# list of countries\n",
    "iso2_countries = coco.convert(unhcr.Country_o.unique(), to='iso2')\n",
    "\n",
    "city_trends_list = []\n",
    "for iso2country in tqdm(iso2_countries):\n",
    "    # get neighbors of country\n",
    "    neighboring_countries = graph.vs[graph.neighborhood(iso2country, order=1)]['name'][1:]\n",
    "\n",
    "    order1_cities = city_topic_ids[city_topic_ids.iso2.isin(neighboring_countries)]\n",
    "\n",
    "    a_country_trends = get_trends_data(iso2country, order1_cities.topic_mid)\n",
    "    a_country_trends['country_o'] = iso2country\n",
    "    # a_country_trends['country_d','city_d'] = order1_cities[['search_keyword','topic_title']]\n",
    "    city_trends_list.append(a_country_trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_topic_ids['citycountry'] = city_topic_ids.topic_title + ', ' + city_topic_ids.search_country\n",
    "city_dict = city_topic_ids.set_index('topic_mid')['citycountry'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_trends_df = pd.DataFrame()\n",
    "for idx, city_trends in enumerate(city_trends_list):\n",
    "    city_trends = city_trends.loc[:, ~city_trends.columns.duplicated()].copy()\n",
    "    city_trends.rename(columns=city_dict, inplace=True)\n",
    "    city_trends_df = pd.concat([city_trends_df, city_trends], axis=0)\n",
    "#semantic_trends_df = semantic_trends_df.reset_index().rename({'index':'date'},axis=1).set_index(['country', 'date'])\n",
    "\n",
    "# Before writing to a csv, make sure that the output makes sense, I think there should be a lot of nas and a lot of columns, one for each country/city topic. \n",
    "# The only ones that aren't na should be the neighboring countries for that country\n",
    "\n",
    "city_trends_df.to_csv('data/city_topic_trends_1.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can gather trends for countries of order 2, excluding order 1 \n",
    "\n",
    "(I think we can skp this part for now. There needs to be some distance-based filter as well that omits far away countries, Looking at Afghanistan for example yields too many countries/cities).\n",
    "\n",
    "this could be obtained by using the location coordinates from geonames-all-cities-with-a-population-1000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_country</th>\n",
       "      <th>search_keyword</th>\n",
       "      <th>topic_title</th>\n",
       "      <th>topic_type</th>\n",
       "      <th>topic_mid</th>\n",
       "      <th>iso2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>City in India</td>\n",
       "      <td>/m/04vmp</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>India</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>City in India</td>\n",
       "      <td>/m/09f07</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>Moscow</td>\n",
       "      <td>Capital of Russia</td>\n",
       "      <td>/m/04swd</td>\n",
       "      <td>RU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>Ho Chi Minh City</td>\n",
       "      <td>Ho Chi Minh City</td>\n",
       "      <td>City in Vietnam</td>\n",
       "      <td>/m/0hn4h</td>\n",
       "      <td>VN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>Hanoi</td>\n",
       "      <td>Hanoi</td>\n",
       "      <td>Capital of Vietnam</td>\n",
       "      <td>/m/0fnff</td>\n",
       "      <td>VN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Iraq</td>\n",
       "      <td>Baghdad</td>\n",
       "      <td>Baghdad</td>\n",
       "      <td>Capital of Iraq</td>\n",
       "      <td>/m/01fqm</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>Saint Petersburg</td>\n",
       "      <td>Saint Petersburg</td>\n",
       "      <td>City in Russia</td>\n",
       "      <td>/m/06pr6</td>\n",
       "      <td>RU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>Capital of Turkey</td>\n",
       "      <td>/m/0jyw</td>\n",
       "      <td>TR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>Almaty</td>\n",
       "      <td>Almaty</td>\n",
       "      <td>City in Kazakhstan</td>\n",
       "      <td>/m/0151s1</td>\n",
       "      <td>KZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Nepal</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Capital of Nepal</td>\n",
       "      <td>/m/04cx5</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Myanmar</td>\n",
       "      <td>Mandalay</td>\n",
       "      <td>Mandalay</td>\n",
       "      <td>City in Myanmar</td>\n",
       "      <td>/m/024bg7</td>\n",
       "      <td>MM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Kazakhstan</td>\n",
       "      <td>Shymkent</td>\n",
       "      <td>Shymkent</td>\n",
       "      <td>City in Kazakhstan</td>\n",
       "      <td>/m/075dh9</td>\n",
       "      <td>KZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>Baku</td>\n",
       "      <td>Baku</td>\n",
       "      <td>Capital of Azerbaijan</td>\n",
       "      <td>/m/01gf5</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>Capital of Armenia</td>\n",
       "      <td>/m/0889d</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Nepal</td>\n",
       "      <td>Bharatpur</td>\n",
       "      <td>Bharatpur</td>\n",
       "      <td>City in India</td>\n",
       "      <td>/m/02r82ff</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>Osh</td>\n",
       "      <td>Osh</td>\n",
       "      <td>City in Kyrgyzstan</td>\n",
       "      <td>/m/04r1h6</td>\n",
       "      <td>KG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Lao People's Dem. Rep.</td>\n",
       "      <td>Vientiane</td>\n",
       "      <td>Vientiane</td>\n",
       "      <td>Capital of Laos</td>\n",
       "      <td>/m/0ftp8</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>Gyumri</td>\n",
       "      <td>Gyumri</td>\n",
       "      <td>Municipality in Armenia</td>\n",
       "      <td>/m/058b5j</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Lao People's Dem. Rep.</td>\n",
       "      <td>Savannakhet</td>\n",
       "      <td>Savannakhet</td>\n",
       "      <td>City in Laos</td>\n",
       "      <td>/m/05d_bs</td>\n",
       "      <td>LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Mongolia</td>\n",
       "      <td>Erdenet</td>\n",
       "      <td>Erdenet</td>\n",
       "      <td>City in Mongolia</td>\n",
       "      <td>/m/03cfzk</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>City in Turkey</td>\n",
       "      <td>/m/09949m</td>\n",
       "      <td>TR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Myanmar</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>City in Myanmar</td>\n",
       "      <td>/m/0fs54</td>\n",
       "      <td>MM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Kyrgyzstan</td>\n",
       "      <td>Bishkek</td>\n",
       "      <td>Bishkek</td>\n",
       "      <td>Capital of Kyrgystan</td>\n",
       "      <td>/m/01g9_</td>\n",
       "      <td>KG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Mongolia</td>\n",
       "      <td>Ulan Bator</td>\n",
       "      <td>Mongolia</td>\n",
       "      <td>UlaanBaatar</td>\n",
       "      <td>/m/0hqkg</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Macau</td>\n",
       "      <td>Macau</td>\n",
       "      <td>Macao</td>\n",
       "      <td>Special administrative regions of China</td>\n",
       "      <td>/m/04thp</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>Sumqayıt</td>\n",
       "      <td>Sumqayit</td>\n",
       "      <td>City in Azerbaijan</td>\n",
       "      <td>/m/034v4t</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>Thimphu</td>\n",
       "      <td>Thimphu</td>\n",
       "      <td>Capital of Bhutan</td>\n",
       "      <td>/m/0ftms</td>\n",
       "      <td>BT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>Phuntsholing</td>\n",
       "      <td>Thimphu</td>\n",
       "      <td>Capital of Bhutan</td>\n",
       "      <td>/m/0ftms</td>\n",
       "      <td>BT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Hong Kong, China</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>Special administrative regions of China</td>\n",
       "      <td>/m/03h64</td>\n",
       "      <td>HK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Iraq</td>\n",
       "      <td>Al Mawşil al Jadīdah</td>\n",
       "      <td>Al Mawsil Al Jadidah</td>\n",
       "      <td>Topic</td>\n",
       "      <td>/g/1trvjxp5</td>\n",
       "      <td>IQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             search_country        search_keyword           topic_title   \n",
       "3                     India                Mumbai                Mumbai  \\\n",
       "7                     India                 Delhi                 Delhi   \n",
       "8        Russian Federation                Moscow                Moscow   \n",
       "12                 Viet Nam      Ho Chi Minh City      Ho Chi Minh City   \n",
       "16                 Viet Nam                 Hanoi                 Hanoi   \n",
       "20                     Iraq               Baghdad               Baghdad   \n",
       "27       Russian Federation      Saint Petersburg      Saint Petersburg   \n",
       "41                   Turkey                Ankara                Ankara   \n",
       "67               Kazakhstan                Almaty                Almaty   \n",
       "86                    Nepal             Kathmandu             Kathmandu   \n",
       "103                 Myanmar              Mandalay              Mandalay   \n",
       "106              Kazakhstan              Shymkent              Shymkent   \n",
       "114              Azerbaijan                  Baku                  Baku   \n",
       "115                 Armenia               Yerevan               Yerevan   \n",
       "179                   Nepal             Bharatpur             Bharatpur   \n",
       "185              Kyrgyzstan                   Osh                   Osh   \n",
       "205  Lao People's Dem. Rep.             Vientiane             Vientiane   \n",
       "215                 Armenia                Gyumri                Gyumri   \n",
       "221  Lao People's Dem. Rep.           Savannakhet           Savannakhet   \n",
       "230                Mongolia               Erdenet               Erdenet   \n",
       "267                  Turkey              Istanbul              İstanbul   \n",
       "271                 Myanmar                Yangon                Yangon   \n",
       "288              Kyrgyzstan               Bishkek               Bishkek   \n",
       "289                Mongolia            Ulan Bator              Mongolia   \n",
       "294                   Macau                 Macau                 Macao   \n",
       "307              Azerbaijan              Sumqayıt              Sumqayit   \n",
       "326                  Bhutan               Thimphu               Thimphu   \n",
       "340                  Bhutan          Phuntsholing               Thimphu   \n",
       "356        Hong Kong, China             Hong Kong             Hong Kong   \n",
       "358                    Iraq  Al Mawşil al Jadīdah  Al Mawsil Al Jadidah   \n",
       "\n",
       "                                  topic_type    topic_mid iso2  \n",
       "3                              City in India     /m/04vmp   IN  \n",
       "7                              City in India     /m/09f07   IN  \n",
       "8                          Capital of Russia     /m/04swd   RU  \n",
       "12                           City in Vietnam     /m/0hn4h   VN  \n",
       "16                        Capital of Vietnam     /m/0fnff   VN  \n",
       "20                           Capital of Iraq     /m/01fqm   IQ  \n",
       "27                            City in Russia     /m/06pr6   RU  \n",
       "41                         Capital of Turkey      /m/0jyw   TR  \n",
       "67                        City in Kazakhstan    /m/0151s1   KZ  \n",
       "86                          Capital of Nepal     /m/04cx5   NP  \n",
       "103                          City in Myanmar    /m/024bg7   MM  \n",
       "106                       City in Kazakhstan    /m/075dh9   KZ  \n",
       "114                    Capital of Azerbaijan     /m/01gf5   AZ  \n",
       "115                       Capital of Armenia     /m/0889d   AM  \n",
       "179                            City in India   /m/02r82ff   NP  \n",
       "185                       City in Kyrgyzstan    /m/04r1h6   KG  \n",
       "205                          Capital of Laos     /m/0ftp8   LA  \n",
       "215                  Municipality in Armenia    /m/058b5j   AM  \n",
       "221                             City in Laos    /m/05d_bs   LA  \n",
       "230                         City in Mongolia    /m/03cfzk   MN  \n",
       "267                           City in Turkey    /m/09949m   TR  \n",
       "271                          City in Myanmar     /m/0fs54   MM  \n",
       "288                     Capital of Kyrgystan     /m/01g9_   KG  \n",
       "289                              UlaanBaatar     /m/0hqkg   MN  \n",
       "294  Special administrative regions of China     /m/04thp   MO  \n",
       "307                       City in Azerbaijan    /m/034v4t   AZ  \n",
       "326                        Capital of Bhutan     /m/0ftms   BT  \n",
       "340                        Capital of Bhutan     /m/0ftms   BT  \n",
       "356  Special administrative regions of China     /m/03h64   HK  \n",
       "358                                    Topic  /g/1trvjxp5   IQ  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighboring_countries = list(set(graph.vs[graph.neighborhood('AF', order=2)]['name']) - set(graph.vs[graph.neighborhood('AF', order=1)]['name']))\n",
    "order2_cities = city_topic_ids[city_topic_ids.iso2.isin(neighboring_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of countries\n",
    "iso2_countries = coco.convert(unhcr.Country_o.unique(), to='iso2')\n",
    "\n",
    "city_trends_list = []\n",
    "for iso2country in tqdm(iso2_countries):\n",
    "    # get neighbors of country of order 2\n",
    "    neighboring_countries = list(set(graph.vs[graph.neighborhood(iso2country, order=2)]['name']) - set(graph.vs[graph.neighborhood(iso2country, order=1)]['name']))\n",
    "    order2_cities = city_topic_ids[city_topic_ids.iso2.isin(neighboring_countries)]\n",
    "\n",
    "    a_country_trends = get_trends_data(iso2country, order1_cities.topic_mid)\n",
    "    a_country_trends['country_o'] = iso2country\n",
    "    a_country_trends['country_d','city_d'] = order1_cities[['search_keyword','topic_title']]\n",
    "    city_trends_list.append(a_country_trends)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refugees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
